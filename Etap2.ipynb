{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbbb0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac01958",
   "metadata": {},
   "source": [
    "Elementy etapu 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838946f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', sep=',', encoding='latin-1',  header=None)\n",
    "df.columns = [\"target\",\"ids\",\"date\",\"flag\",\"user\",\"text\"]\n",
    "df = df.drop([\"ids\",\"date\",\"flag\",\"user\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3131ee",
   "metadata": {},
   "source": [
    "1.1 Konwersja tekstu do małych liter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc3bc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  @switchfoot http://twitpic.com/2y1zl - awww, t...\n",
       "1       0  is upset that he can't update his facebook by ...\n",
       "2       0  @kenichan i dived many times for the ball. man...\n",
       "3       0    my whole body feels itchy and like its on fire \n",
       "4       0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeb44b1",
   "metadata": {},
   "source": [
    "1.2 Usuwanie znaków interpunkcyjnych i specjalnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc3fa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>switchfoot httptwitpiccom2y1zl  awww thats a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kenichan i dived many times for the ball manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  switchfoot httptwitpiccom2y1zl  awww thats a b...\n",
       "1       0  is upset that he cant update his facebook by t...\n",
       "2       0  kenichan i dived many times for the ball manag...\n",
       "3       0    my whole body feels itchy and like its on fire \n",
       "4       0  nationwideclass no its not behaving at all im ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "df['text'] = df['text'].apply(lambda x: str(x).translate(translator))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1bbb9",
   "metadata": {},
   "source": [
    "1.3 Usuwanie stop słów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8377457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Staś\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Create a set of stop words \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# Define a function to remove stop words from a sentence \n",
    "def remove_stop_words(sentence): \n",
    "    # Split the sentence into individual words \n",
    "    words = sentence.split() \n",
    "    # Use a list comprehension to remove stop words \n",
    "    filtered_words = [word for word in words if word not in stop_words] \n",
    "      # Join the filtered words back into a sentence \n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "370ba556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>switchfoot httptwitpiccom2y1zl awww thats bumm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>kenichan dived many times ball managed save 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwideclass behaving im mad cant see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  switchfoot httptwitpiccom2y1zl awww thats bumm...\n",
       "1       0  upset cant update facebook texting might cry r...\n",
       "2       0  kenichan dived many times ball managed save 50...\n",
       "3       0                   whole body feels itchy like fire\n",
       "4       0           nationwideclass behaving im mad cant see"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(lambda x: remove_stop_words(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5cbaa",
   "metadata": {},
   "source": [
    "1.4 Tokenizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2ce19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Staś\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da2d7817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, thats,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[upset, cant, update, facebook, texting, might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[kenichan, dived, many, times, ball, managed, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[nationwideclass, behaving, im, mad, cant, see]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  [switchfoot, httptwitpiccom2y1zl, awww, thats,...\n",
       "1       0  [upset, cant, update, facebook, texting, might...\n",
       "2       0  [kenichan, dived, many, times, ball, managed, ...\n",
       "3       0            [whole, body, feels, itchy, like, fire]\n",
       "4       0    [nationwideclass, behaving, im, mad, cant, see]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbebc35",
   "metadata": {},
   "source": [
    "Podział na zbiór testowy i treningowy (z etapu 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c715f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257b102",
   "metadata": {},
   "source": [
    "2 Wykorzystanie metody Bag-of-Words (BoW) do przekształcenia tekstu na wektory cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31394c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW_train = pd.Series([y for x in train_df['text'].values.flatten() for y in x]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7efbec17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "im                      124522\n",
       "good                     62507\n",
       "day                      57553\n",
       "get                      57062\n",
       "like                     54422\n",
       "                         ...  \n",
       "httptwitpiccom61djw          1\n",
       "mrscottiebee                 1\n",
       "httptinyurlcomkj4lyh         1\n",
       "akmanning                    1\n",
       "maeundead                    1\n",
       "Length: 660662, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoW_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9954cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW_test = pd.Series([y for x in test_df['text'].values.flatten() for y in x]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ad45992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "im                 52958\n",
       "good               26891\n",
       "day                24812\n",
       "get                24422\n",
       "like               23326\n",
       "                   ...  \n",
       "nshollingsworth        1\n",
       "cazza                  1\n",
       "hibbsy                 1\n",
       "jenthefangirls         1\n",
       "intrasite              1\n",
       "Length: 357847, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoW_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c6154",
   "metadata": {},
   "source": [
    "3.1 Naiwny klasyfikator Bayesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a7d6daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przetworzono batch 1/113\n",
      "Przetworzono batch 2/113\n",
      "Przetworzono batch 3/113\n",
      "Przetworzono batch 4/113\n",
      "Przetworzono batch 5/113\n",
      "Przetworzono batch 6/113\n",
      "Przetworzono batch 7/113\n",
      "Przetworzono batch 8/113\n",
      "Przetworzono batch 9/113\n",
      "Przetworzono batch 10/113\n",
      "Przetworzono batch 11/113\n",
      "Przetworzono batch 12/113\n",
      "Przetworzono batch 13/113\n",
      "Przetworzono batch 14/113\n",
      "Przetworzono batch 15/113\n",
      "Przetworzono batch 16/113\n",
      "Przetworzono batch 17/113\n",
      "Przetworzono batch 18/113\n",
      "Przetworzono batch 19/113\n",
      "Przetworzono batch 20/113\n",
      "Przetworzono batch 21/113\n",
      "Przetworzono batch 22/113\n",
      "Przetworzono batch 23/113\n",
      "Przetworzono batch 24/113\n",
      "Przetworzono batch 25/113\n",
      "Przetworzono batch 26/113\n",
      "Przetworzono batch 27/113\n",
      "Przetworzono batch 28/113\n",
      "Przetworzono batch 29/113\n",
      "Przetworzono batch 30/113\n",
      "Przetworzono batch 31/113\n",
      "Przetworzono batch 32/113\n",
      "Przetworzono batch 33/113\n",
      "Przetworzono batch 34/113\n",
      "Przetworzono batch 35/113\n",
      "Przetworzono batch 36/113\n",
      "Przetworzono batch 37/113\n",
      "Przetworzono batch 38/113\n",
      "Przetworzono batch 39/113\n",
      "Przetworzono batch 40/113\n",
      "Przetworzono batch 41/113\n",
      "Przetworzono batch 42/113\n",
      "Przetworzono batch 43/113\n",
      "Przetworzono batch 44/113\n",
      "Przetworzono batch 45/113\n",
      "Przetworzono batch 46/113\n",
      "Przetworzono batch 47/113\n",
      "Przetworzono batch 48/113\n",
      "Przetworzono batch 49/113\n",
      "Przetworzono batch 50/113\n",
      "Przetworzono batch 51/113\n",
      "Przetworzono batch 52/113\n",
      "Przetworzono batch 53/113\n",
      "Przetworzono batch 54/113\n",
      "Przetworzono batch 55/113\n",
      "Przetworzono batch 56/113\n",
      "Przetworzono batch 57/113\n",
      "Przetworzono batch 58/113\n",
      "Przetworzono batch 59/113\n",
      "Przetworzono batch 60/113\n",
      "Przetworzono batch 61/113\n",
      "Przetworzono batch 62/113\n",
      "Przetworzono batch 63/113\n",
      "Przetworzono batch 64/113\n",
      "Przetworzono batch 65/113\n",
      "Przetworzono batch 66/113\n",
      "Przetworzono batch 67/113\n",
      "Przetworzono batch 68/113\n",
      "Przetworzono batch 69/113\n",
      "Przetworzono batch 70/113\n",
      "Przetworzono batch 71/113\n",
      "Przetworzono batch 72/113\n",
      "Przetworzono batch 73/113\n",
      "Przetworzono batch 74/113\n",
      "Przetworzono batch 75/113\n",
      "Przetworzono batch 76/113\n",
      "Przetworzono batch 77/113\n",
      "Przetworzono batch 78/113\n",
      "Przetworzono batch 79/113\n",
      "Przetworzono batch 80/113\n",
      "Przetworzono batch 81/113\n",
      "Przetworzono batch 82/113\n",
      "Przetworzono batch 83/113\n",
      "Przetworzono batch 84/113\n",
      "Przetworzono batch 85/113\n",
      "Przetworzono batch 86/113\n",
      "Przetworzono batch 87/113\n",
      "Przetworzono batch 88/113\n",
      "Przetworzono batch 89/113\n",
      "Przetworzono batch 90/113\n",
      "Przetworzono batch 91/113\n",
      "Przetworzono batch 92/113\n",
      "Przetworzono batch 93/113\n",
      "Przetworzono batch 94/113\n",
      "Przetworzono batch 95/113\n",
      "Przetworzono batch 96/113\n",
      "Przetworzono batch 97/113\n",
      "Przetworzono batch 98/113\n",
      "Przetworzono batch 99/113\n",
      "Przetworzono batch 100/113\n",
      "Przetworzono batch 101/113\n",
      "Przetworzono batch 102/113\n",
      "Przetworzono batch 103/113\n",
      "Przetworzono batch 104/113\n",
      "Przetworzono batch 105/113\n",
      "Przetworzono batch 106/113\n",
      "Przetworzono batch 107/113\n",
      "Przetworzono batch 108/113\n",
      "Przetworzono batch 109/113\n",
      "Przetworzono batch 110/113\n",
      "Przetworzono batch 111/113\n",
      "Przetworzono batch 112/113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = []\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    text = df['text'][i]\n",
    "    text = ''.join(text)\n",
    "    X.append(text)\n",
    "\n",
    "y= df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "           X, y, test_size = 0.3, random_state = 0)\n",
    "    \n",
    "vectorizer = TfidfVectorizer(max_features = 1500)\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "batch_size = 10000\n",
    "num_batches = X_train_vec.shape[0] // batch_size + 1\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start = i * batch_size\n",
    "    end = min((i + 1) * batch_size, X_train_vec.shape[0])\n",
    "    if start >= end:\n",
    "        break\n",
    "    X_batch = X_train_vec[start:end]\n",
    "    y_batch = y_train.iloc[start:end]\n",
    "        \n",
    "    # W przypadku pierwszej iteracji używamy `partial_fit` z initial classes\n",
    "    if i == 0:\n",
    "        model.partial_fit(X_batch, y_batch, classes=np.array([0, 4]))\n",
    "    else:\n",
    "        model.partial_fit(X_batch, y_batch)\n",
    "    print(f\"Przetworzono batch {i + 1}/{num_batches}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "596a98de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ewaluacja modelu na zbiorze testowym\u001b[39;00m\n\u001b[0;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_vec)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDokładność modelu:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43maccuracy_score\u001b[49m(y_test, y_pred))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaport klasyfikacji:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, classification_report(y_test, y_pred))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    " vectorizer\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    print(\"Dokładność modelu:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Raport klasyfikacji:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d789a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
