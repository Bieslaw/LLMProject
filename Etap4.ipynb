{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela została utworzona pomyślnie.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    dbname=\"SentimentDB\",\n",
    "    user=\"Kuba\",\n",
    "    password=\"kuba\",\n",
    "    host=\"localhost\",  # lub adres serwera\n",
    "    port=\"5432\"        # domyślny port PostgreSQL\n",
    ")\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE tweets (\n",
    "    id BIGINT PRIMARY KEY,          -- Kolumna ID jako klucz główny\n",
    "    text TEXT NOT NULL,            -- Kolumna text\n",
    "    tokens TEXT NOT NULL,        -- Kolumna tokens jako tablica tekstowa\n",
    "    target INTEGER NOT NULL,       -- Kolumna target\n",
    "    cnn_pred INTEGER NOT NULL,     -- Kolumna cnn_pred\n",
    "    mistrall_pred Integer          -- Kolumna mistrall_pred\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor = connection.cursor()\n",
    "try:\n",
    "    cursor.execute(create_table_query)\n",
    "    connection.commit()\n",
    "    print(\"Tabela została utworzona pomyślnie.\")\n",
    "except Exception as e:\n",
    "    print(\"Błąd podczas tworzenia tabeli:\", e)\n",
    "finally:\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane zostały załadowane pomyślnie.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "df = pd.read_csv('CNN_tweet_prediction.csv', sep=',', encoding='latin-1')\n",
    "df['mistrall_pred'] = -1\n",
    "\n",
    "engine = create_engine('postgresql://Kuba:kuba@localhost:5432/SentimentDB')\n",
    "\n",
    "try:\n",
    "    df.to_sql('tweets', engine, if_exists='append', index=False)\n",
    "    print(\"Dane zostały załadowane pomyślnie.\")\n",
    "except Exception as e:\n",
    "    print(f\"Wystąpił błąd podczas ładowania danych: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_batch(batch_texts, model, client, log = False):\n",
    "    def format_tweets_for_prompt(tweets):\n",
    "        formatted_tweets = \"\\n\".join([f\"Tweet {i + 1}: \\\"{tweet}\\\"\" for i, tweet in enumerate(tweets)])\n",
    "        return formatted_tweets\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Classify the following {len(batch_texts)} tweets to determine if their sentiment is positive or negative. Only respond with the list of exact words 'positive' or 'negative', in the same order as the tweets are provided, separated by commas.\n",
    "            I am providing you {len(batch_texts)} tweets, so you must return as a answear list which lenght is also {len(batch_texts)}.\n",
    "            Tweets:\n",
    "            {format_tweets_for_prompt(batch_texts)}\"\"\"\n",
    "        },\n",
    "    ]\n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    response = chat_response.choices[0].message.content\n",
    "    \n",
    "    if log:\n",
    "        print(f\"[MIstrall AI] Message content: {messages[0]}\")\n",
    "        print(f\"[MIstrall AI] response: {response}\")\n",
    "    \n",
    "    sentiments = response.split(\",\")  # Podział odpowiedzi na listę\n",
    "    if(len(sentiments) != len(batch_texts)):\n",
    "        raise Exception(\"Mismatch between number of tweets and sentiments returned.\")\n",
    "    return [1 if s.strip().lower() == \"positive\" else 0 for s in sentiments]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetwarzanie danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import time\n",
    "\n",
    "def process_and_update_data(engine, model, client, batch_size = 100, log = False):\n",
    "    select_query = text(\"\"\"\n",
    "            SELECT * FROM tweets\n",
    "            WHERE mistrall_pred = -1\n",
    "            ORDER BY ID ASC\n",
    "            LIMIT :batch_size;\n",
    "        \"\"\")\n",
    "    \n",
    "    update_query = text(\"\"\"\n",
    "        UPDATE tweets\n",
    "        SET mistrall_pred = :mistrall_pred\n",
    "        WHERE id = :id;\n",
    "    \"\"\")\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        while True:\n",
    "            batch = pd.read_sql(select_query, conn, params={\"batch_size\": batch_size})\n",
    "\n",
    "            if batch.empty:\n",
    "                print(\"[DONE] ALL RECORD PROCESSED\")\n",
    "                break\n",
    "            \n",
    "            min_id = batch['id'].min()\n",
    "            max_id = batch['id'].max()\n",
    "\n",
    "            batch_texts = batch['text'].tolist()\n",
    "\n",
    "            try:\n",
    "                sentiments = process_batch(batch_texts, model, client, log)  # Przekazujemy 0 jako iter\n",
    "                \n",
    "                if sentiments is None:\n",
    "                    raise Exception(\"[Mistrall AI] empty answear\")\n",
    "                    continue\n",
    "\n",
    "                batch['mistrall_pred'] = sentiments\n",
    "\n",
    "                for _, row in batch.iterrows():\n",
    "                    if log:\n",
    "                        print(f\"Zapis do rekordu ID={row['id']}, mistrall_pred= {row['mistrall_pred']}\")\n",
    "                    conn.execute(update_query, {\"mistrall_pred\": row['mistrall_pred'], \"id\": row['id']})\n",
    "                conn.commit()\n",
    "\n",
    "                print(f\"[DB-COMMIT] Processed and updated {len(batch)} records. IDs: [{min_id},{max_id}]\")\n",
    "                time.sleep(1.5)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR]: {e} Records: [{min_id},{max_id}] will be processed in next iteration\")\n",
    "                time.sleep(1.5)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB-COMMIT] Processed and updated 10 records. IDs: [692,701]\n",
      "[DB-COMMIT] Processed and updated 10 records. IDs: [702,711]\n",
      "[DB-COMMIT] Processed and updated 10 records. IDs: [712,721]\n",
      "[DB-COMMIT] Processed and updated 10 records. IDs: [722,731]\n",
      "[DB-COMMIT] Processed and updated 10 records. IDs: [732,741]\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [742,751] will be processed in next iteration\n",
      "[DB-COMMIT] Processed and updated 10 records. IDs: [742,751]\n",
      "[DB-COMMIT] Processed and updated 10 records. IDs: [752,761]\n",
      "[DB-COMMIT] Processed and updated 10 records. IDs: [762,771]\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [772,781] will be processed in next iteration\n",
      "[DB-COMMIT] Processed and updated 10 records. IDs: [772,781]\n",
      "[DB-COMMIT] Processed and updated 10 records. IDs: [782,791]\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [792,801] will be processed in next iteration\n",
      "[DB-COMMIT] Processed and updated 10 records. IDs: [792,801]\n",
      "[DB-COMMIT] Processed and updated 10 records. IDs: [802,811]\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n",
      "[ERROR]: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"} Records: [812,821] will be processed in next iteration\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSDKError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 33\u001b[0m, in \u001b[0;36mprocess_and_update_data\u001b[1;34m(engine, model, client, batch_size, log)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     sentiments \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Przekazujemy 0 jako iter\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sentiments \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[124], line 18\u001b[0m, in \u001b[0;36mprocess_batch\u001b[1;34m(batch_texts, model, client, log)\u001b[0m\n\u001b[0;32m      9\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     {\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     },\n\u001b[0;32m     17\u001b[0m ]\n\u001b[1;32m---> 18\u001b[0m chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m response \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\jakuw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mistralai\\chat.py:148\u001b[0m, in \u001b[0;36mChat.complete\u001b[1;34m(self, model, messages, temperature, top_p, max_tokens, stream, stop, random_seed, response_format, tools, tool_choice, presence_penalty, frequency_penalty, n, safe_prompt, retries, server_url, timeout_ms, http_headers)\u001b[0m\n\u001b[0;32m    147\u001b[0m     http_res_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mstream_to_text(http_res)\n\u001b[1;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m models\u001b[38;5;241m.\u001b[39mSDKError(\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI error occurred\u001b[39m\u001b[38;5;124m\"\u001b[39m, http_res\u001b[38;5;241m.\u001b[39mstatus_code, http_res_text, http_res\n\u001b[0;32m    150\u001b[0m     )\n\u001b[0;32m    152\u001b[0m content_type \u001b[38;5;241m=\u001b[39m http_res\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mSDKError\u001b[0m: API error occurred: Status 429\n{\"message\":\"Requests rate limit exceeded\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m client \u001b[38;5;241m=\u001b[39m Mistral(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[0;32m      8\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mprocess_and_update_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[125], line 52\u001b[0m, in \u001b[0;36mprocess_and_update_data\u001b[1;34m(engine, model, client, batch_size, log)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[ERROR]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Records: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] will be processed in next iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "DB_URL = 'postgresql://Kuba:kuba@localhost:5432/SentimentDB'\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "api_key = \"zdRaC8ptWSvAIBCmP84ImOAWfbY2ZIbj\"\n",
    "model = \"open-mistral-nemo\"\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "process_and_update_data(\n",
    "    engine=engine,\n",
    "    model=model,\n",
    "    client=client,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    log=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
