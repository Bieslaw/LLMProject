{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższą część skryptu należy wykonać jedynie za pierwszym razem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    dbname=\"SentimentDB\", # podaj nazwę bazy\n",
    "    user=\"Kuba\",          # podaj username\n",
    "    password=\"kuba\",      # podaj haslo\n",
    "    host=\"localhost\",     # adres serwera\n",
    "    port=\"5432\"           # port\n",
    ")\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE tweets (\n",
    "    id BIGINT PRIMARY KEY,          -- Kolumna ID jako klucz główny\n",
    "    text TEXT NOT NULL,             -- Kolumna text\n",
    "    tokens TEXT NOT NULL,           -- Kolumna tokens jako tablica tekstowa\n",
    "    target INTEGER NOT NULL,        -- Kolumna target\n",
    "    cnn_pred INTEGER NOT NULL,      -- Kolumna cnn_pred\n",
    "    mistrall_pred Integer           -- Kolumna mistrall_pred\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor = connection.cursor()\n",
    "try:\n",
    "    cursor.execute(create_table_query)\n",
    "    connection.commit()\n",
    "    print(\"Tabela została utworzona pomyślnie.\")\n",
    "except Exception as e:\n",
    "    print(\"Błąd podczas tworzenia tabeli:\", e)\n",
    "finally:\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższy skrypt należy również wykonać dokładnie raz. Ładuje on dane z pliku do utworzonej tabeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "df = pd.read_csv('CNN_tweet_prediction.csv', sep=',', encoding='latin-1')\n",
    "df['mistrall_pred'] = -1\n",
    "\n",
    "engine = create_engine('postgresql://Kuba:kuba@localhost:5432/SentimentDB')\n",
    "\n",
    "try:\n",
    "    df.to_sql('tweets', engine, if_exists='append', index=False)\n",
    "    print(\"Dane zostały załadowane pomyślnie.\")\n",
    "except Exception as e:\n",
    "    print(f\"Wystąpił błąd podczas ładowania danych: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższa częśc skryptu odpowiedzialna jest za batchowe nadawanie sentymentów tweetom.\\\n",
    "1. process_batch - funkcja wysyła prompta do Mistrall AI z liczbą tweetów jaką mamy w batchu. \n",
    "2. process_and_update_data - funkcja pobiera z tabeli liczbę rekordów równą rozmiarowi batcha. Pobierane są rekordy dla których mistrall_pred = -1 (nie zostały jeszcze sklasyfikowane).\\\n",
    "Rekordy są posortowane po ID rosnąco.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "import pandas as pd\n",
    "\n",
    "def process_batch(batch_texts, model, client, log = False):\n",
    "    def format_tweets_for_prompt(tweets):\n",
    "        formatted_tweets = \"\\n\".join([f\"Tweet {i + 1}: \\\"{tweet}\\\"\" for i, tweet in enumerate(tweets)])\n",
    "        return formatted_tweets\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Classify the following {len(batch_texts)} tweets to determine if their sentiment is positive or negative. Only respond with the list of exact words 'positive' or 'negative', in the same order as the tweets are provided, separated by commas.\n",
    "            I am providing you {len(batch_texts)} tweets, so you must return as a answear list which lenght is also {len(batch_texts)}.\n",
    "            Tweets:\n",
    "            {format_tweets_for_prompt(batch_texts)}\"\"\"\n",
    "        },\n",
    "    ]\n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    response = chat_response.choices[0].message.content\n",
    "    \n",
    "    if log:\n",
    "        print(f\"[MIstrall AI] Message content: {messages[0]}\")\n",
    "        print(f\"[MIstrall AI] response: {response}\")\n",
    "    \n",
    "    sentiments = response.split(\",\")  # Podział odpowiedzi na listę\n",
    "    if(len(sentiments) != len(batch_texts)):\n",
    "        raise Exception(\"Mismatch between number of tweets and sentiments returned.\")\n",
    "    return [1 if s.strip().lower() == \"positive\" else 0 for s in sentiments]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetwarzanie danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import time\n",
    "\n",
    "def process_and_update_data(engine, model, client, batch_size = 100, log = False):\n",
    "    select_query = text(\"\"\"\n",
    "            SELECT * FROM tweets\n",
    "            WHERE mistrall_pred = -1\n",
    "            ORDER BY ID ASC\n",
    "            LIMIT :batch_size;\n",
    "        \"\"\")\n",
    "    \n",
    "    update_query = text(\"\"\"\n",
    "        UPDATE tweets\n",
    "        SET mistrall_pred = :mistrall_pred\n",
    "        WHERE id = :id;\n",
    "    \"\"\")\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        while True:\n",
    "            batch = pd.read_sql(select_query, conn, params={\"batch_size\": batch_size})\n",
    "\n",
    "            if batch.empty:\n",
    "                print(\"[DONE] ALL RECORD PROCESSED\")\n",
    "                break\n",
    "            \n",
    "            min_id = batch['id'].min()\n",
    "            max_id = batch['id'].max()\n",
    "\n",
    "            batch_texts = batch['text'].tolist()\n",
    "\n",
    "            try:\n",
    "                sentiments = process_batch(batch_texts, model, client, log)  # Przekazujemy 0 jako iter\n",
    "                \n",
    "                if sentiments is None:\n",
    "                    raise Exception(\"[Mistrall AI] empty answear\")\n",
    "                    continue\n",
    "\n",
    "                batch['mistrall_pred'] = sentiments\n",
    "\n",
    "                for _, row in batch.iterrows():\n",
    "                    if log:\n",
    "                        print(f\"Zapis do rekordu ID={row['id']}, mistrall_pred= {row['mistrall_pred']}\")\n",
    "                    conn.execute(update_query, {\"mistrall_pred\": row['mistrall_pred'], \"id\": row['id']})\n",
    "                conn.commit()\n",
    "\n",
    "                print(f\"[DB-COMMIT] Processed and updated {len(batch)} records. IDs: [{min_id},{max_id}]\")\n",
    "                time.sleep(1.5)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR]: {e} Records: [{min_id},{max_id}] will be processed in next iteration\")\n",
    "                time.sleep(1.5)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruchomienie kubełkowego przetwarzania danych. Należy ustawić następujące parametry:\\\n",
    "1. DB_URL - URL do bazy w której znajduje się tabela z danymi.\n",
    "2. api_key - Klucz API do Mistrall AI\n",
    "3. model - model Mistrala - \"open-mistral-nemo\" wydaje się być ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DB_URL = 'postgresql://Kuba:kuba@localhost:5432/SentimentDB'\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "api_key = \"...\"\n",
    "model = \"open-mistral-nemo\"\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "process_and_update_data(\n",
    "    engine=engine,\n",
    "    model=model,\n",
    "    client=client,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    log=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
